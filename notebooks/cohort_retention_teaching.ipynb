{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-000",
      "source": "# Cohort Retention Teaching Notebook (v1.2)\n\nThis notebook teaches you how to **explain the cohort retention decision story yourself** using the real project outputs.\n\n## Learning goal\nBy the end, you should be able to explain:\n1. What decision is being supported\n2. Why the evidence is trustworthy (Gates A/B/C + QA)\n3. What each chart means\n4. Which families to prioritize and why (directional, not causal)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-001",
      "source": "## Story structure you should memorize\nUse this sequence when presenting:\n1. **Decision**: what choice the business needs to make\n2. **Trust checks**: prove data quality before charts\n3. **Chart 1**: overall retention shape by cohort and month\n4. **Chart 2**: net proxy behavior (refund-aware)\n5. **Chart 3**: family-level priority ranking\n6. **Actions**: 2 plays and how to measure them\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-001",
      "source": "## Instructor mode: how to use this notebook\nRead this like a lecture, not like a script to memorize line-by-line.\n\n### Teaching cadence (recommended)\n- 2 minutes: decision and business context\n- 2 minutes: trust checks and gate discipline\n- 4 minutes: chart walkthrough (1 minute per chart + transitions)\n- 2 minutes: recommendation and guardrails\n\n### Golden rule while speaking\nAlways separate:\n- **Observed fact** (what the data says)\n- **Interpretation** (what it might mean)\n- **Action** (what we will test next)\n\nThat structure keeps your story rigorous and avoids accidental causal claims.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-002",
      "execution_count": null,
      "outputs": [],
      "source": "from pathlib import Path\nimport json\nimport re\nimport pandas as pd\n\n# Robust repo root detection for notebook and nbconvert execution contexts.\ncwd = Path.cwd().resolve()\nREPO_ROOT = None\nfor root in [cwd] + list(cwd.parents):\n    if (root / 'data_processed').exists() and (root / 'docs').exists():\n        REPO_ROOT = root\n        break\nif REPO_ROOT is None:\n    raise FileNotFoundError('Could not locate repo root with data_processed/ and docs/.')\n\nDP = REPO_ROOT / 'data_processed'\nDOCS = REPO_ROOT / 'docs'\nEXPORTS = REPO_ROOT / 'exports'\n\nrequired = [\n    DP / 'customer_month_activity.csv',\n    DP / 'orders.csv',\n    DP / 'customers.csv',\n    DP / 'gate_a.json',\n    DP / 'confound_m2_family_all_vs_retail.csv',\n    DP / 'chart1_logo_retention_heatmap.csv',\n    DP / 'chart2_net_proxy_curves.csv',\n    DP / 'chart3_m2_by_family.csv',\n    DOCS / 'DRIVER_COVERAGE_REPORT.md',\n    DOCS / 'QA_CHECKLIST.md',\n    DOCS / 'DECISION_MEMO_1PAGE.md',\n    EXPORTS / 'cohort_retention_story.html',\n]\nmissing = [str(p.relative_to(REPO_ROOT)) for p in required if not p.exists()]\nif missing:\n    raise FileNotFoundError('Missing required artifacts: ' + ', '.join(missing))\n\ncma = pd.read_csv(DP / 'customer_month_activity.csv')\norders = pd.read_csv(DP / 'orders.csv')\ncustomers = pd.read_csv(DP / 'customers.csv')\nchart1 = pd.read_csv(DP / 'chart1_logo_retention_heatmap.csv')\nchart2 = pd.read_csv(DP / 'chart2_net_proxy_curves.csv')\nchart3 = pd.read_csv(DP / 'chart3_m2_by_family.csv')\nconfound = pd.read_csv(DP / 'confound_m2_family_all_vs_retail.csv')\ngate_a = json.loads((DP / 'gate_a.json').read_text(encoding='ascii'))\n\ncoverage_text = (DOCS / 'DRIVER_COVERAGE_REPORT.md').read_text(encoding='ascii')\nqa_text = (DOCS / 'QA_CHECKLIST.md').read_text(encoding='utf-8')\n\nm_gross = re.search(r'mapped to non-Other families: ([0-9]+\\.?[0-9]*)%', coverage_text)\nm_customer = re.search(r'customers with non-Other first_product_family: ([0-9]+\\.?[0-9]*)%', coverage_text)\ncoverage_gross = float(m_gross.group(1)) if m_gross else None\ncoverage_customer = float(m_customer.group(1)) if m_customer else None\n\nprint('Repo root:', REPO_ROOT)\nprint('Loaded rows -> cma:', len(cma), 'orders:', len(orders), 'customers:', len(customers))\nprint('Loaded chart tables -> chart1:', len(chart1), 'chart2:', len(chart2), 'chart3:', len(chart3))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "terms-001",
      "source": "## Terminology Masterclass (speak these fluently)\nUse this section to build vocabulary precision. In interviews and reviews, terminology clarity is a credibility multiplier.\n\nWhen you define a term, always include:\n1. What it is\n2. How it is computed\n3. Why it matters\n4. What people often misunderstand\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "terms-002",
      "execution_count": null,
      "outputs": [],
      "source": "terms = pd.DataFrame([\n    {\n        'term': 'Cohort',\n        'plain_english': 'A group of customers bucketed by first valid purchase month.',\n        'how_computed': 'cohort_month = month(first_order_ts) for non-guest customers with >=1 valid purchase',\n        'why_it_matters': 'Lets us compare retention trajectories fairly across customer start periods.',\n        'common_misread': 'Treating cohorts as static segments rather than time-anchored start groups.'\n    },\n    {\n        'term': 'months_since_first (0..6)',\n        'plain_english': 'How many months after the cohort month we are measuring.',\n        'how_computed': 'Period(M) difference: activity_month - cohort_month, constrained to 0..6',\n        'why_it_matters': 'Aligns customer timelines so Month 2 means the same lifecycle stage for everyone.',\n        'common_misread': 'Mixing calendar month with lifecycle month.'\n    },\n    {\n        'term': 'Logo retention',\n        'plain_english': 'Whether a customer placed any valid purchase in a given month (0/1).',\n        'how_computed': 'is_retained_logo = 1 if orders_count_valid > 0 else 0',\n        'why_it_matters': 'Captures repeat behavior independent of basket size.',\n        'common_misread': 'Assuming retained logo implies strong revenue quality.'\n    },\n    {\n        'term': 'Net retention proxy',\n        'plain_english': 'Refund-aware value proxy normalized by month-0 gross baseline.',\n        'how_computed': 'sum(net_revenue_proxy_total_t) / sum(gross_revenue_valid_t0), cohort-level',\n        'why_it_matters': 'Shows value dynamics beyond pure repeat incidence.',\n        'common_misread': 'Treating it as audited finance profit metric.'\n    },\n    {\n        'term': 'first_product_family (driver)',\n        'plain_english': 'Primary family inferred from the customer first valid order.',\n        'how_computed': 'Max gross family within first valid order; NonMerch excluded from competition',\n        'why_it_matters': 'Creates action-oriented entry-point segmentation for retention tests.',\n        'common_misread': 'Thinking it is a stable preference label forever.'\n    },\n    {\n        'term': 'is_credit_like',\n        'plain_english': 'Order flagged as refund/credit behavior.',\n        'how_computed': 'is_cancel_invoice OR order_net_proxy < 0',\n        'why_it_matters': 'Prevents mixing credits into positive sale interpretation.',\n        'common_misread': 'Ignoring credits and overstating value retention.'\n    },\n    {\n        'term': 'Gate A',\n        'plain_english': 'Validity trigger for strict purchase rules.',\n        'how_computed': '% valid purchases with net<=0; trigger if >0.5%',\n        'why_it_matters': 'Protects cohort definitions from financially inconsistent purchases.',\n        'common_misread': 'Assuming default validity is always safe.'\n    },\n    {\n        'term': 'Gate B',\n        'plain_english': 'Coverage quality of product-family mapping.',\n        'how_computed': '% gross mapped to non-Other + customer non-Other coverage',\n        'why_it_matters': 'Ensures driver segmentation is informative, not mostly Other.',\n        'common_misread': 'Optimizing for perfect mapping at cost of rule bloat.'\n    },\n    {\n        'term': 'Gate C',\n        'plain_english': 'Sensitivity check for wholesale-like confounding.',\n        'how_computed': 'Compare M2 family retention: All vs Retail-only; material if >=5pp & n>=80',\n        'why_it_matters': 'Separates true signal from segment-mix distortion risk.',\n        'common_misread': 'Treating non-material differences as meaningful.'\n    },\n])\n\npd.set_option('display.max_colwidth', 120)\nprint(terms.to_string(index=False))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "terms-003",
      "source": "### Terminology drill (say this out loud)\n- \"A cohort is defined by first valid purchase month; months_since_first aligns lifecycle, not calendar.\"\n- \"Logo retention measures repeat incidence, while net retention proxy measures refund-aware value dynamics.\"\n- \"first_product_family is the frozen entry-point driver for prioritization, not a causal label.\"\n- \"Gate A/B/C are controls for validity, mapping coverage, and confound sensitivity before interpretation.\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "newbie-001",
      "source": "## Noobie One-Pass Map (memorize this first)\nIf everything feels like too much, reduce the whole project to 5 boxes:\n\n1. **Question**: Which first-product families should we test first for retention?\n2. **Trust**: Did Gates A/B/C and QA checks pass?\n3. **Pattern**: What do the 3 charts say (overall trend, value trend, family ranking)?\n4. **Decision**: Which 2-3 families do we prioritize now?\n5. **Action**: What 2 experiments run next + what guardrails we monitor?\n\nIf you can say one sentence for each box, you can explain the project.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "newbie-002",
      "source": "### Fill-in-the-blank speaking template (practice)\nUse this template until it becomes automatic:\n\n- \"We analyzed cohorts to decide ________.\"\n- \"Before interpretation, we validated quality with Gate A/B/C: ________.\"\n- \"Chart 1 shows ________.\"\n- \"Chart 2 shows ________, which matters because ________.\"\n- \"Chart 3 shows top families ________ and weaker families ________.\"\n- \"So the immediate plays are ________ and ________, measured by ________, with guardrails ________.\"\n- \"This is directional, not causal, because ________.\"\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "newbie-003",
      "execution_count": null,
      "outputs": [],
      "source": "# Quick story card: one-screen summary you can read before presenting\nmaterial_count = int(confound['material_sensitivity'].sum()) if 'material_sensitivity' in confound.columns else 0\nbest = chart3.sort_values('m2_logo_retention', ascending=False, kind='stable').iloc[0]\nweak = chart3.sort_values('m2_logo_retention', ascending=True, kind='stable').iloc[0]\n\nstory_card = {\n    'Decision': 'Prioritize first_product_family segments for retention tests',\n    'Gate A': f\"{gate_a['gate_a_pct_valid_nonpositive_net']:.4f}% non-positive valid net (trigger={gate_a['trigger_fired']})\",\n    'Gate B': f\"{coverage_gross:.2f}% gross mapped non-Other; {coverage_customer:.2f}% customers non-Other\",\n    'Gate C': f\"material sensitivity count={material_count}\",\n    'Top family': f\"{best['family_group']} ({best['m2_logo_retention']*100:.1f}%, n={int(best['n_customers'])})\",\n    'Weak family': f\"{weak['family_group']} ({weak['m2_logo_retention']*100:.1f}%, n={int(weak['n_customers'])})\",\n}\nfor k, v in story_card.items():\n    print(f\"- {k}: {v}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-003",
      "source": "## 1) Decision framing (say this first)\n**Decision to support:** Which `first_product_family` groups should we prioritize for retention tests (replenishment nudges + returns mitigation)?\n\n**Primary KPI in decision chart:** M2 logo retention (`months_since_first == 2`)\n\n**Secondary KPI for risk context:** Net retention proxy (refund-aware, directional)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-002",
      "source": "### Lecture note: why this decision framing works\nMost analytics stories fail because they start with methods, not decisions.\n\nHere, start with one sentence:\n> \"We are deciding which first-product-family segments to test first for retention gains.\"\n\nThen translate business risk:\n- If we choose wrong families, experiment budget is wasted.\n- If we choose right families, we accelerate learning and retention impact.\n\nThis creates immediate relevance before any technical detail.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-004",
      "execution_count": null,
      "outputs": [],
      "source": "summary = pd.DataFrame([\n    {\n        'question': 'Which first_product_family should be prioritized for retention experiments?',\n        'primary_kpi': 'M2 logo retention',\n        'secondary_kpi': 'net retention proxy',\n        'horizon': 'months 0..6',\n        'driver': 'first_product_family only',\n    }\n])\nprint(summary.to_string(index=False))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-005",
      "source": "## 2) Trust checks before charts\nYou should always prove these checks pass before talking about conclusions.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-003",
      "source": "### Lecture note: what each trust check protects against\n- **Uniqueness checks** prevent accidental double-counting.\n- **Full grid check (7 rows/customer)** ensures denominator consistency across months.\n- **Month 0 = 100%** validates cohort construction logic.\n- **Non-negative sale proxy** prevents mislabeled credits as sales.\n\nHow to phrase it in a presentation:\n> \"Before interpretation, we validated structural integrity so the trends are not artifacts of data shape.\"\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-006",
      "execution_count": null,
      "outputs": [],
      "source": "rows_per_customer = cma.groupby('customer_id').size()\nmonth0 = cma[cma['months_since_first'] == 0]\nsale_nonnegative = (orders.loc[orders['is_credit_like'] == 0, 'order_net_proxy'] >= 0).all()\n\nchecks = pd.DataFrame([\n    {'check': 'orders.order_id unique', 'pass': bool(orders['order_id'].is_unique)},\n    {'check': 'customers.customer_id unique', 'pass': bool(customers['customer_id'].is_unique)},\n    {'check': 'full grid = 7 rows/customer', 'pass': bool((rows_per_customer == 7).all())},\n    {'check': 'Month0 logo retention = 100%', 'pass': bool((month0['is_retained_logo'] == 1).all())},\n    {'check': 'non-credit order_net_proxy non-negative', 'pass': bool(sale_nonnegative)},\n])\nprint(checks.to_string(index=False))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-007",
      "source": "## 3) Gate receipts (A/B/C)\nUse these three lines to establish methodological discipline.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-004",
      "source": "### Lecture note: how to explain Gates A/B/C in plain language\n- **Gate A (validity)**: checks whether purchases marked valid are financially coherent.\n- **Gate B (coverage)**: checks whether product-family mapping is specific enough to drive decisions.\n- **Gate C (confound sensitivity)**: checks if wholesale-like behavior is distorting family comparisons.\n\nWhen asked \"Why should we trust this?\", answer with the gates first, charts second.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-008",
      "execution_count": null,
      "outputs": [],
      "source": "material_count = int(confound['material_sensitivity'].sum()) if 'material_sensitivity' in confound.columns else 0\nprint(f\"Gate A: {gate_a['gate_a_pct_valid_nonpositive_net']:.4f}% valid purchases with non-positive net; trigger={gate_a['trigger_fired']}\")\nprint(f\"Gate B: gross coverage non-Other={coverage_gross:.2f}%, customer non-Other={coverage_customer:.2f}%\")\nprint(f\"Gate C: material sensitivity count={material_count} (rows={len(confound)})\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-009",
      "source": "## 4) Chart 1 teaching points (logo retention heatmap)\nWhat to say:\n- \"This chart shows the retention shape across cohorts over months 0..6.\"\n- \"Month 0 is mechanically ~100% by cohort definition.\"\n- \"Look for faster vs slower decay across cohort rows.\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-005",
      "source": "### How to narrate Chart 1 confidently\nSpeak in three passes:\n1. **Orientation**: \"Rows are cohorts, columns are months since first purchase.\"\n2. **Pattern**: \"Retention decays over time; that is expected.\"\n3. **Implication**: \"The question becomes where decay is slower and more recoverable.\"\n\nAvoid overfitting one cohort row; focus on repeated patterns across cohorts.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-010",
      "execution_count": null,
      "outputs": [],
      "source": "heat = chart1.copy()\nheat['months_since_first'] = heat['months_since_first'].astype(int)\nmonth2 = heat[heat['months_since_first'] == 2].copy()\nmonth6 = heat[heat['months_since_first'] == 6].copy()\nmean_m2 = month2['logo_retention'].mean()\nmean_m6 = month6['logo_retention'].mean()\nprint(f'Average logo retention at Month 2 across cohorts: {mean_m2:.3f}')\nprint(f'Average logo retention at Month 6 across cohorts: {mean_m6:.3f}')\nprint('Interpretation: Month 6 lower than Month 2 indicates expected retention decay over time.')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-011",
      "source": "## 5) Chart 2 teaching points (net retention proxy curves)\nWhat to say:\n- \"These are eligible cohorts only (baseline denominator guard applied).\"\n- \"Net proxy can diverge from logo retention because refunds/credits affect value even when logos retain.\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-006",
      "source": "### How to narrate Chart 2 without confusion\nCommon audience confusion: \"Why does logo retention look okay while net proxy drops?\"\n\nTeaching answer:\n- Logo retention only asks \"did they buy?\"\n- Net proxy asks \"what was the value after returns/credits?\"\n\nSo divergence is not contradictory; it indicates value leakage risk despite repeat behavior.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-012",
      "execution_count": null,
      "outputs": [],
      "source": "m2 = chart2[chart2['months_since_first'] == 2].copy().sort_values('m2_logo_retention', ascending=False, kind='stable').reset_index(drop=True)\nprint('Cohorts used in Chart 2 (ranked by M2 logo retention):')\nprint(m2[['cohort_month', 'n_customers', 'm2_logo_retention', 'net_retention_proxy']].to_string(index=False))\n\nif len(m2) >= 2:\n    top = m2.iloc[0]\n    bot = m2.iloc[-1]\n    print(f\"Top vs bottom M2 logo gap: {(top['m2_logo_retention'] - bot['m2_logo_retention']) * 100:.1f}pp\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-013",
      "source": "## 6) Chart 3 teaching points (M2 retention by first family)\nWhat to say:\n- \"This is the prioritization chart: which first families have stronger/weaker M2 repeat?\"\n- \"Bars are annotated with n so we can balance signal strength vs sample size.\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-007",
      "source": "### How to narrate Chart 3 for decision-making\nUse this framing:\n- \"This is a **prioritization** chart, not a causal attribution chart.\"\n- \"We choose where to test first based on M2 signal strength and sample size.\"\n- \"Top bars suggest replenishment opportunities; lower bars suggest friction/returns mitigation opportunities.\"\n\nAlways mention `n_customers` when comparing bars.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-014",
      "execution_count": null,
      "outputs": [],
      "source": "fam = chart3.sort_values(['m2_logo_retention', 'n_customers'], ascending=[False, False], kind='stable').reset_index(drop=True)\nprint('Family ranking used for action prioritization:')\nprint(fam.to_string(index=False))\n\ntop3 = fam.head(3)\nbottom2 = fam.tail(2)\nprint('\\nTop 3 candidate families for retention tests:')\nprint(top3[['family_group', 'm2_logo_retention', 'n_customers']].to_string(index=False))\nprint('\\nLower-performing families to consider for returns/credit mitigation:')\nprint(bottom2[['family_group', 'm2_logo_retention', 'n_customers']].to_string(index=False))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-015",
      "source": "## 7) Confounds and limitations (must state aloud)\n- Findings are **directional, not causal**.\n- `first_product_family` is derived from text mapping and can be imperfect.\n- NonMerch (`*_NonMerch`) is excluded from first-family competition by design.\n- Gate C compares All vs Retail-only to check wholesale-like sensitivity.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-008",
      "source": "### Objection handling (interview-safe)\nIf challenged, use these responses:\n\n- **\"Is this causal?\"**\n  No. It is directional segmentation evidence; causal claims require controlled experiments.\n\n- **\"Could mapping bias this?\"**\n  Yes, partially. That is why Gate B coverage is monitored and rules are auditable.\n\n- **\"Could wholesale behavior skew this?\"**\n  We run Gate C All vs Retail-only sensitivity and report material differences.\n\n- **\"Why only 0..6 months?\"**\n  Horizon is frozen by spec for comparability and complete customer-month grids.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-016",
      "execution_count": null,
      "outputs": [],
      "source": "qa_pass = {\n    'full_grid_pass': 'customer_month_activity has exactly 7 rows/customer for months 0..6 PASS' in qa_text,\n    'month0_pass': 'Month0 logo retention ~100% (after exclusions) PASS' in qa_text,\n    'credit_alignment_pass': 'is_credit_like applied to orders.financial_status and transactions.kind PASS' in qa_text,\n}\nprint('QA receipt flags:', qa_pass)\nprint('Confound material sensitivity count:', int(confound['material_sensitivity'].sum()) if 'material_sensitivity' in confound.columns else 'N/A')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-017",
      "source": "## 8) 60-second talk track generator\nRun the next cell and practice reading it out loud. Keep this structure in interviews:\n1) Decision\n2) Trust checks\n3) 3 chart takeaways\n4) Action plays + guardrails\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-009",
      "source": "### Turn the talk track into a repeatable explanation\nPractice in this exact order:\n1. One-line decision\n2. Three gate receipts\n3. One line per chart\n4. Two test plays\n5. One caveat sentence (directional, not causal)\n\nIf you can do this in under 60 seconds with confidence, your story is interview-ready.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "cell-018",
      "execution_count": null,
      "outputs": [],
      "source": "gate_a_pct = gate_a['gate_a_pct_valid_nonpositive_net']\nmaterial_count = int(confound['material_sensitivity'].sum()) if 'material_sensitivity' in confound.columns else 0\n\nbest = chart3.sort_values('m2_logo_retention', ascending=False, kind='stable').iloc[0]\nworst = chart3.sort_values('m2_logo_retention', ascending=True, kind='stable').iloc[0]\nspread_pp = (best['m2_logo_retention'] - worst['m2_logo_retention']) * 100\n\nscript_lines = [\n    \"Decision: prioritize first_product_family cohorts for retention experiments.\",\n    f\"Data trust: Gate A {gate_a_pct:.4f}% (trigger={gate_a['trigger_fired']}), Gate B {coverage_gross:.2f}% mapped, Gate C material={material_count}.\",\n    \"Chart 1: cohort retention decays over months 0..6, as expected.\",\n    \"Chart 2: net proxy curves show value-level divergence beyond logo retention.\",\n    f\"Chart 3: best family {best['family_group']} ({best['m2_logo_retention']*100:.1f}%, n={int(best['n_customers'])}), weakest {worst['family_group']} ({worst['m2_logo_retention']*100:.1f}%, n={int(worst['n_customers'])}), spread {spread_pp:.1f}pp.\",\n    \"Action: run replenishment nudges on top families and returns/credit mitigation on weaker families.\",\n    \"Caveat: directional evidence only, not causal proof.\"\n]\nfor i, line in enumerate(script_lines, start=1):\n    print(f\"{i}. {line}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cell-019",
      "source": "## Practice checklist for yourself\nBefore presenting, confirm you can answer:\n- Why Month 0 is ~100%\n- Why net proxy can move differently from logo retention\n- Why family ranking is a prioritization heuristic (not causal truth)\n- What experiment you would run first and what guardrail you would watch\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "lecture-010",
      "source": "## Self-quiz (answer out loud)\n1. Why is Month 0 expected to be 100%?\n2. What does Gate B protect against?\n3. Why can net proxy fall while logo retention stays stable?\n4. What makes Chart 3 actionable but non-causal?\n5. What are the two immediate plays and their guardrails?\n\nIf you can answer these cleanly, you can explain the cohort decision story end-to-end.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "quiz-001",
      "source": "## Mini Quiz (self-check)\nTry answering without looking up the notebook.\n\n1. What does `months_since_first = 2` mean in plain English?\n2. Why do we require a full 0..6 grid for each cohort customer?\n3. What business risk does Gate B protect against?\n4. Why can logo retention stay stable while net proxy drops?\n5. What is the single driver used for family segmentation in this project?\n6. Name the two action plays and one guardrail for each.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "quiz-002",
      "source": "### Mini Quiz Answer Key (grade yourself)\n1. Month 2 means two lifecycle months after first valid purchase month.\n2. Full grid prevents denominator drift and makes month-to-month comparisons valid.\n3. Gate B protects against `Other` dominating and making segmentation too vague for decisions.\n4. Logo is incidence (did buy), net proxy is value after returns/credits.\n5. Driver is `first_product_family` only.\n6. Plays: replenishment nudges (guardrail: no rise in credits/cancellations), returns/credits mitigation (guardrail: margin/support burden).\n\nScoring:\n- 6/6: ready to present solo\n- 4-5/6: review terminology + Chart 2 explanation\n- <=3/6: re-read Noobie One-Pass Map and repeat talk-track cell\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}